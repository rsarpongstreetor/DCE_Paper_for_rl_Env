{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsarpongstreetor/DCE_Paper_for_rl_Env/blob/main/optimized_copy_of_Fuel_price_Environment_MARLANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gorqaRJWGLD4",
        "outputId": "bb51c932-c9f9-461f-cd46-9d7f81e2c2a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting torchrl\n",
            "  Downloading torchrl-0.5.0-cp310-cp310-manylinux1_x86_64.whl.metadata (33 kB)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchrl) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchrl) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchrl) (24.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from torchrl) (2.2.1)\n",
            "Collecting tensordict>=0.5.0 (from torchrl)\n",
            "  Downloading tensordict-0.5.0-cp310-cp310-manylinux1_x86_64.whl.metadata (22 kB)\n",
            "Collecting torch>=2.3.0 (from torchrl)\n",
            "  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting orjson (from tensordict>=0.5.0->torchrl)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (12.1.105)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.3.0->torchrl)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (12.1.105)\n",
            "Collecting triton==3.0.0 (from torch>=2.3.0->torchrl)\n",
            "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.3.0->torchrl) (12.6.20)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->torchrl) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.3.0->torchrl) (1.3.0)\n",
            "Downloading torchrl-0.5.0-cp310-cp310-manylinux1_x86_64.whl (987 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m988.0/988.0 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensordict-0.5.0-cp310-cp310-manylinux1_x86_64.whl (336 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.1/336.1 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, orjson, nvidia-cudnn-cu12, torch, tensordict, torchrl\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.1\n",
            "    Uninstalling triton-2.3.1:\n",
            "      Successfully uninstalled triton-2.3.1\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n",
            "    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.1+cu121\n",
            "    Uninstalling torch-2.3.1+cu121:\n",
            "      Successfully uninstalled torch-2.3.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 2.4.0 which is incompatible.\n",
            "torchvision 0.18.1+cu121 requires torch==2.3.1, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cudnn-cu12-9.1.0.70 orjson-3.10.7 tensordict-0.5.0 torch-2.4.0 torchrl-0.5.0 triton-3.0.0\n",
            "Requirement already satisfied: tensordict in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from tensordict) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensordict) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from tensordict) (2.2.1)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from tensordict) (3.10.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.4.0->tensordict) (12.6.20)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->tensordict) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.4.0->tensordict) (1.3.0)\n",
            "Collecting torchview\n",
            "  Downloading torchview-0.2.6-py3-none-any.whl.metadata (12 kB)\n",
            "Downloading torchview-0.2.6-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: torchview\n",
            "Successfully installed torchview-0.2.6\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Collecting torch==2.3.1 (from torchvision)\n",
            "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (12.1.105)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1->torchvision)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (12.1.105)\n",
            "Collecting triton==2.3.1 (from torch==2.3.1->torchvision)\n",
            "  Using cached triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1->torchvision) (12.6.20)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.1->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.1->torchvision) (1.3.0)\n",
            "Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "Installing collected packages: triton, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.0.0\n",
            "    Uninstalling triton-3.0.0:\n",
            "      Successfully uninstalled triton-3.0.0\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.0\n",
            "    Uninstalling torch-2.4.0:\n",
            "      Successfully uninstalled torch-2.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch\n",
        "!pip3 install torchrl\n",
        "!pip3 install tensordict\n",
        "!pip3 install torchview\n",
        "!pip3 install torchvision\n",
        "!pip3 install pydrive\n",
        "!pip3 install ipython-autotime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBdvI114pYjy",
        "outputId": "6b7db1cb-c6e1-406e-8cf7-44d5fc823ab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import multiprocessing\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import nn\n",
        "from tensordict.nn import TensorDictModule\n",
        "from tensordict.nn.distributions import NormalParamExtractor\n",
        "\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data.replay_buffers import ReplayBuffer\n",
        "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
        "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
        "from torchrl.envs import (Compose, DoubleToFloat, ObservationNorm, StepCounter,TransformedEnv )\n",
        "from torchrl.envs.libs.gym import GymEnv\n",
        "from torchrl.envs.utils import check_env_specs, ExplorationType, set_exploration_type\n",
        "from torchrl.modules import ProbabilisticActor, TanhNormal, ValueOperator\n",
        "from torchrl.objectives import ClipPPOLoss\n",
        "from torchrl.objectives.value import GAE\n",
        "from tqdm import tqdm\n",
        "import google.colab\n",
        "import pygame\n",
        "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete\n",
        "import random\n",
        "import os\n",
        "import math\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets\n",
        "from google.colab import drive\n",
        "google.colab.drive.mount('/content/drive')\n",
        "from collections import defaultdict\n",
        "from typing import Optional\n",
        "import torchrl\n",
        "import numpy as np\n",
        "from tensordict import TensorDict, TensorDictBase\n",
        "from torchrl.modules import MultiAgentConvNet\n",
        "from torchrl.data import BoundedTensorSpec, CompositeSpec, UnboundedContinuousTensorSpec,DiscreteTensorSpec\n",
        "from torchrl.envs import (\n",
        "    CatTensors,\n",
        "    EnvBase,\n",
        "    Transform,\n",
        "    TransformedEnv,\n",
        "    UnsqueezeTransform,\n",
        ")\n",
        "\n",
        "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
        "from torchrl.envs.utils import check_env_specs, step_mdp\n",
        "import tensordict as td\n",
        "from torchrl.envs import EnvBase\n",
        "from torch import  tensor\n",
        "from torchrl.envs.transforms import TransformedEnv\n",
        "import tensordict\n",
        "\n",
        "from torchrl.envs import RewardSum, TransformedEnv\n",
        "from torchrl.envs.libs.vmas import VmasEnv\n",
        "from torchrl.envs.utils import check_env_specs\n",
        "\n",
        "# Multi-agent network\n",
        "from torchrl.modules import MultiAgentMLP, ProbabilisticActor, TanhNormal\n",
        "\n",
        "# Loss\n",
        "from torchrl.objectives import ClipPPOLoss, ValueEstimators\n",
        "\n",
        "# Utils\n",
        "torch.manual_seed(0)\n",
        "from matplotlib import pyplot as plt\n",
        "from typing import Union, Sequence, Type\n",
        "\n",
        "import torch.nn as nn\n",
        "from torchrl.envs.utils import check_env_specs, step_mdp\n",
        "from torchrl.modules import ProbabilisticActor\n",
        "#####################################\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4JWCT6vHpY_d"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import numpy as np  # Import NumPy\n",
        "k=0\n",
        "\n",
        "class DDataenv():\n",
        "\n",
        "  #Initialize\n",
        "  def __init__(self):\n",
        "    # Load data here\n",
        "      self.DDDDataDic =np.empty((8,7), dtype=np.float32)\n",
        "      # We have 3 actions, corresponding to \"increase\", \"decrease\", \"no change \" in fuel price\n",
        "      #self.action_space = spaces.Discrete(3)\n",
        "      # Observations are dictionaries with the agent's Observation which are.\n",
        "      # Forex, Crude oil pric, Fuel price, reward, action\n",
        "      self.vvmm=np.empty((8,10), dtype=np.float32)\n",
        "      self.k=k\n",
        "\n",
        "  def _downl_Data(self):\n",
        "        with open('/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/solutions/mergedata/DataDic.pt','rb') as rpp:\n",
        "          DataDic = torch.load(rpp)\n",
        "        DDataDic=DataDic[0]\n",
        "        DDDDataDic=DDataDic\n",
        "        return DDDDataDic\n",
        "\n",
        "  def _get_obs_stats(self):\n",
        "        self.vvmm_dict = {}\n",
        "        observation=[]\n",
        "        vvmm_dict={},\n",
        "        vvnn=[]\n",
        "        vvnv={}\n",
        "        DD=[]\n",
        "        DDDataDic=[]\n",
        "        aadd={}\n",
        "        aadd1={}\n",
        "        aadd2={}\n",
        "\n",
        "        aabb=[]\n",
        "        actionState=[]\n",
        "        rewardState=[]\n",
        "        obsState=[]\n",
        "        obsFuels=[]\n",
        "        rewardFuels=[]\n",
        "        actionFuels=[]\n",
        "        Envvstatesinput=[]\n",
        "        Envvfuelsinput=[]\n",
        "         #observation\n",
        "        DDDataDic=self._downl_Data()\n",
        "        observation=DDDataDic[np.random.choice(DDDataDic.shape[0], 1, replace=False),:].numpy().astype(np.float32)\n",
        "        observation.flatten()\n",
        "        aabb=pd.DataFrame(observation)\n",
        "        aabb.transpose()\n",
        "        aabb.columns=['Forex','WTI','Brent','OPEC','Fuelprice5','Fuelprice6','Fuelprice7','Fuelprice8','Fuelprice9','Fuelprice10','Fuelprice11','Fuelprice12','Fuelprice13',\n",
        "                     'reward0','reward1','reward2','reward3','reward4','reward5','reward6','reward7','reward8','reward9','reward10','reward11','reward12',\n",
        "                    'action0','action1','action2','action3','action4','action5','action6','action7','action8','action9','action10','action11','action12',]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        obsState=np.array(aabb.iloc[0,0:4])\n",
        "        rewardState=np.array(aabb.iloc[0,13:17])\n",
        "        actionState=np.array(aabb.iloc[0,26:30])\n",
        "        obsfuels=np.array(aabb.iloc[0,4:13])\n",
        "        rewardfuels=np.array(aabb.iloc[0,17:26])\n",
        "        actionfuels=np.array(aabb.iloc[0,30:39])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        aadd1=pd.concat((pd.Series(obsState),pd.Series(rewardState),pd.Series(actionState)),axis=1)\n",
        "\n",
        "        aadd1=pd.DataFrame(aadd1)\n",
        "        aadd1.columns=['obsState','rewardState','actionState']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        aadd2=pd.concat([pd.Series(obsfuels),pd.Series(rewardfuels),pd.Series(actionfuels)],axis=1)\n",
        "\n",
        "        aadd2=pd.DataFrame(aadd2)\n",
        "        aadd2.columns=['obsFuels','rewardFuels','actionFuels']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        obsState_max=[]\n",
        "        obsState_min=[]\n",
        "        rewardState_max=[]\n",
        "        rewardState_min=[]\n",
        "        actionState_max=[]\n",
        "        actionState_min=[]\n",
        "        obsfuels_max=[]\n",
        "        obsfuels_min=[]\n",
        "        rewardfuels_max=[]\n",
        "        rewardfuels_min=[]\n",
        "        actionfuels_max=[]\n",
        "        actionfuels_min=[]\n",
        "\n",
        "\n",
        "        DD = DDDataDic.clone()\n",
        "        DD.reshape(-1, DD.shape[-1])\n",
        "        vvmm=np.zeros((8,DD.shape[1]))\n",
        "        df = pd.DataFrame(DD)\n",
        "\n",
        "        vvmm = df.describe()\n",
        "        vvmm.columns=['Forex','WTI','Brent','OPEC','Fuelprice5','Fuelprice6','Fuelprice7','Fuelprice8','Fuelprice9','Fuelprice10','Fuelprice11','Fuelprice12','Fuelprice13',\n",
        "                      'reward0','reward1','reward2','reward3','reward4','reward5','reward6','reward7','reward8','reward9','reward10','reward11','reward12',\n",
        "                      'action0','action1','action2','action3','action4','action5','action6','action7','action8','action9','action10','action11','action12',]\n",
        "\n",
        "        vvmm.index=['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
        "        vvmm1=pd.concat((vvmm.iloc[:,0:4],vvmm.iloc[:,13:17],vvmm.iloc[:,26:30]),axis=1)\n",
        "        vvmm2=pd.concat((vvmm.iloc[:,4:13] ,vvmm.iloc[:,17:26],vvmm.iloc[:,30:39]),axis=1)\n",
        "\n",
        "        vvmm1.index=['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
        "        vvmm2.index=['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        ii= [3, 7]\n",
        "       # vvmm.astype(dtype=np.float32, copy=True, errors='list')\n",
        "        xx1=[]\n",
        "        yy1=[]\n",
        "        xxx1=[]\n",
        "        yyy1=[]\n",
        "        vvvv1=[]\n",
        "\n",
        "        for k in range(len(vvmm1.columns)):\n",
        "          for i in ii:\n",
        "            xx1.append(vvmm1.iat[i, k])\n",
        "\n",
        "\n",
        "        for k in range(len(vvmm1.columns)):\n",
        "          for i in ii:\n",
        "            yy1.append(str(vvmm1.index[i]) + '.' + str(vvmm1.columns[k]))\n",
        "\n",
        "        xx1=np.array(xx1)\n",
        "        xx1 = xx1.reshape(1,24)\n",
        "\n",
        "        yyy1=iter(yy1)\n",
        "        vvnn1=pd.DataFrame(xx1,dtype=np.float32)\n",
        "\n",
        "\n",
        "        vvnn1.columns=yyy1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for j in range(24):\n",
        "          if j < 4:\n",
        "            obsState_min.append(((vvnn1.iloc[0,2*j  :2*j+1]).squeeze()))\n",
        "            obsState_max.append(((vvnn1.iloc[0,2*j+1:2*j+2]).squeeze()))\n",
        "            rewardState_min.append(((vvnn1.iloc[0,2*j+8:2*j+9]).squeeze()))\n",
        "            rewardState_max.append(((vvnn1.iloc[0,2*j+9:2*j+10]).squeeze()))\n",
        "            actionState_min.append(((vvnn1.iloc[0,2*j+16:2*j+17]).squeeze()))\n",
        "            actionState_max.append(((vvnn1.iloc[0,2*j+17:2*j+18]).squeeze()))\n",
        "\n",
        "\n",
        "        ii= [3, 7]\n",
        "       # vvmm.astype(dtype=np.float32, copy=True, errors='list')\n",
        "        xx2=[]\n",
        "        yy2=[]\n",
        "        xxx2=[]\n",
        "        yyy2=[]\n",
        "        vvvv2=[]\n",
        "\n",
        "        for k in range(len(vvmm2.columns)):\n",
        "          for i in ii:\n",
        "            xx2.append(vvmm2.iat[i, k])\n",
        "\n",
        "\n",
        "        for k in range(len(vvmm2.columns)):\n",
        "          for i in ii:\n",
        "            yy2.append(str(vvmm2.index[i]) + '.' + str(vvmm2.columns[k]))\n",
        "\n",
        "        xx2=np.array(xx2)\n",
        "        xx2 = xx2.reshape(1,54)\n",
        "\n",
        "        yyy2=iter(yy2)\n",
        "        vvnn2=pd.DataFrame(xx2,dtype=np.float32)\n",
        "\n",
        "\n",
        "        vvnn2.columns=yyy2\n",
        "\n",
        "\n",
        "\n",
        "        for j in range(54):\n",
        "          if j < 9:\n",
        "            obsfuels_max.append(((vvnn2.iloc[0,2*j:2*j+1])))\n",
        "            obsfuels_min.append(((vvnn2.iloc[0,2*j+1:2*j+2])))\n",
        "\n",
        "            rewardfuels_min.append(((vvnn2.iloc[0,2*j+17:2*j+18])))\n",
        "            rewardfuels_max.append(((vvnn2.iloc[0,2*j+18:2*j+19])))\n",
        "\n",
        "            actionfuels_max.append(((vvnn2.iloc[0,2*j+36:2*j+37])))\n",
        "            actionfuels_min.append(((vvnn2.iloc[0,2*j+37:2*j+38])))\n",
        "\n",
        "        obsfuels_max=np.array(obsfuels_max).reshape(-1)\n",
        "        obsfuels_min=np.array(obsfuels_min).reshape(-1)\n",
        "        actionfuels_max=np.array(actionfuels_max).reshape(-1)\n",
        "        actionfuels_min=np.array(actionfuels_min).reshape(-1)\n",
        "        rewardfuels_max=np.array(rewardfuels_max).reshape(-1)\n",
        "        rewardfuels_min=np.array(rewardfuels_min).reshape(-1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        vvmm1_dict=pd.concat([pd.Series(obsState_max),pd.Series(obsState_min),pd.Series(rewardState_max),pd.Series(rewardState_min),pd.Series(actionState_max),pd.Series(actionState_min)],axis=1)\n",
        "\n",
        "        vvmm1_dict.columns=['obsState_max','obsState_min','rewardState_max','rewardState_min','actionState_max','actionState_min']\n",
        "\n",
        "        vvmm2_dict=pd.concat([pd.Series(obsfuels_max),pd.Series(obsfuels_min),pd.Series(rewardfuels_max),pd.Series(rewardfuels_min),pd.Series(actionfuels_max),pd.Series(actionfuels_min)],axis=1)\n",
        "\n",
        "        vvmm2_dict.columns=['obsFuels_min','obsFuels_max','rewardFuels_min','rewardFuels_max','actionFuels_min','actionFuels_max']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        fv=pd.concat((vvmm2_dict,aadd2),axis=1)\n",
        "        sv=pd.concat((vvmm1_dict,aadd1),axis=1)\n",
        "        ssv=np.zeros((9,9))\n",
        "        ssv=pd.DataFrame(ssv)\n",
        "        ssv.columns=sv.columns\n",
        "        sssv=sv+ssv\n",
        "        sv=sssv\n",
        "        svfv=pd.concat((sv,fv),axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #result=pd.concat([aadd1,vvmm1_dict], axis=1)\n",
        "        #result.columns=['obsState','actionState','reward','obsState_max','obsState_min','rewardState_max','rewardState_min','actionState_max','actionState_min']\n",
        "       # result2=pd.concat([aadd2,vvnn2], axis=1)\n",
        "       # resulttensor=torch.tensor(result.to_numpy())\n",
        "        #print(resulttensor)\n",
        "        result=svfv.to_dict(orient='list')\n",
        "\n",
        "        return result\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UF--TTWOJGES"
      },
      "outputs": [],
      "source": [
        "my_object=DDataenv()\n",
        "rresult=my_object._get_obs_stats()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j20g_A2DL5xi"
      },
      "source": [
        "Environment"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nbO470pQem3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_54ypbFEfMtv"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7Zx2x045vsf",
        "outputId": "45b702ee-7c16-41fd-a249-6063fb4b7a98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.]]], dtype=torch.float64)\n",
            "\n",
            "*action_spec: CompositeSpec(\n",
            "    agents: CompositeSpec(\n",
            "        action: BoundedTensorSpec(\n",
            "            shape=torch.Size([1, 9, 5]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([1, 9, 5]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([1, 9, 5]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([1])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([1]))\n",
            "\n",
            "*reward_spec: CompositeSpec(\n",
            "    agents: CompositeSpec(\n",
            "        reward: BoundedTensorSpec(\n",
            "            shape=torch.Size([1, 9, 5]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([1, 9, 5]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([1, 9, 5]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([1])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([1]))\n",
            "\n",
            "*done_spec: CompositeSpec(\n",
            "    done: DiscreteTensorSpec(\n",
            "        shape=torch.Size([1, 9]),\n",
            "        space=DiscreteBox(n=2),\n",
            "        device=cpu,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    terminated: DiscreteTensorSpec(\n",
            "        shape=torch.Size([1, 9]),\n",
            "        space=DiscreteBox(n=2),\n",
            "        device=cpu,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([1]))\n",
            "\n",
            "*observation_spec: CompositeSpec(\n",
            "    agents: CompositeSpec(\n",
            "        observation: BoundedTensorSpec(\n",
            "            shape=torch.Size([1, 9, 5]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([1, 9, 5]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([1, 9, 5]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([1])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([1]))\n",
            "\n",
            "-action_keys: [('agents', 'action')]\n",
            "\n",
            "-reward_keys: [('agents', 'reward')]\n",
            "\n",
            "-done_keys: ['done', 'terminated']\n",
            "input_spec: CompositeSpec(\n",
            "    full_state_spec: CompositeSpec(\n",
            "    ,\n",
            "        device=cpu,\n",
            "        shape=torch.Size([1])),\n",
            "    full_action_spec: CompositeSpec(\n",
            "        agents: CompositeSpec(\n",
            "            action: BoundedTensorSpec(\n",
            "                shape=torch.Size([1, 9, 5]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([1, 9, 5]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([1, 9, 5]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            device=cpu,\n",
            "            shape=torch.Size([1])),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([1])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([1]))\n",
            "action_spec (as defined by input_spec): BoundedTensorSpec(\n",
            "    shape=torch.Size([1, 9, 5]),\n",
            "    space=ContinuousBox(\n",
            "        low=Tensor(shape=torch.Size([1, 9, 5]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "        high=Tensor(shape=torch.Size([1, 9, 5]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "    device=cpu,\n",
            "    dtype=torch.float32,\n",
            "    domain=continuous)\n",
            "reward_spec: BoundedTensorSpec(\n",
            "    shape=torch.Size([1, 9, 5]),\n",
            "    space=ContinuousBox(\n",
            "        low=Tensor(shape=torch.Size([1, 9, 5]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "        high=Tensor(shape=torch.Size([1, 9, 5]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "    device=cpu,\n",
            "    dtype=torch.float32,\n",
            "    domain=continuous)\n",
            "reset tensordict TensorDict(\n",
            "    fields={\n",
            "        agents: TensorDict(\n",
            "            fields={\n",
            "                observation: Tensor(shape=torch.Size([1, 9, 5]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "            batch_size=torch.Size([1]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([1, 9]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([1, 9]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([1]),\n",
            "    device=cpu,\n",
            "    is_shared=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-08-26 15:41:38,486 [torchrl][INFO] check_env_specs succeeded!\n"
          ]
        }
      ],
      "source": [
        "def _step(tensordict):\n",
        "    # ...\n",
        "    td=env.gen_params()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Extract the necessary DataFrames from rresult\n",
        "    # Extract the variables needed in _make_spec\n",
        "    n_agents =  env.n_agents\n",
        "    agent_tds = []\n",
        "    agents = [{} for _ in range(n_agents)]\n",
        "    # Collect observations in a list first\n",
        "    # Iterate over the DataFrame\n",
        "\n",
        "    for i in range(n_agents):\n",
        "        # Initialize lists to store data for each agent within the batch\n",
        "        agent_i_obs = []\n",
        "        agent_i_action = []\n",
        "        agent_i_rew = []\n",
        "        agent_i_new_obs = []\n",
        "\n",
        "        agent_obs_list=[]\n",
        "        agent_reward_list=[]\n",
        "        agent_action_list=[]\n",
        "        newobs_obs_list=[]\n",
        "\n",
        "        for j in range(env.batch_size[0]):\n",
        "            obsState=td['params','obsState'].clone().detach()\n",
        "            rewardState=td['params','rewardState'].clone().detach()\n",
        "            actionState=td['params','actionState'].clone().detach()\n",
        "            obsFuels=td['params','obsFuels'].clone().detach().unsqueeze((-1))\n",
        "            rewardFuels=td['params','rewardFuels'].clone().detach().unsqueeze((-1))\n",
        "            actionFuels=td['params','actionFuels'].clone().detach().unsqueeze((-1))\n",
        "            obs=[]\n",
        "            reward=[]\n",
        "            action=[]\n",
        "            obsj=[]\n",
        "            rewardj=[]\n",
        "            actionj=[]\n",
        "            newobs=[]\n",
        "            obs=torch.cat(((torch.mul((obsState[0:4]),torch.ones(len(obsFuels),1))),obsFuels),dim=1)\n",
        "            reward=torch.cat(((torch.mul((rewardState[0:4]),torch.ones(len(obsFuels),1))),rewardFuels),dim=1)\n",
        "            action=torch.cat(((torch.mul((actionState[0:4]),torch.ones(len(obsFuels),1))),actionFuels),dim=1)\n",
        "            for i,[agent_obs,agent_reward,agent_action], in enumerate(zip(obs,reward,action)):\n",
        "                agent_reward_list.append(agent_reward)\n",
        "                agent_action_list.append(agent_action)\n",
        "                newobs=torch.add(agent_obs,((agent_action)*agent_reward))\n",
        "                newobs_obs_list.append(newobs)\n",
        "\n",
        "                torch.stack(agent_reward_list, dim=1)\n",
        "                torch.stack(agent_action_list, dim=1)\n",
        "                torch.stack(newobs_obs_list, dim=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            obsj.append(newobs_obs_list)\n",
        "            rewardj.append(agent_reward_list)\n",
        "            actionj.append(agent_action_list)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        agent_reward = torch.stack([torch.stack(inner_list) for inner_list in rewardj], dim=0)\n",
        "        agent_action = torch.stack([torch.stack(inner_list) for inner_list in actionj], dim=0)\n",
        "        agent_obs = torch.stack([torch.stack(inner_list) for inner_list in  obsj], dim=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # Ensure agent_obs_tensor has the correct batch dimension\n",
        "        observation  = agent_obs.float()\n",
        "        episode_reward  = agent_reward.float()\n",
        "        agent_action_tensor =  agent_action.float()\n",
        "\n",
        "\n",
        "\n",
        "    dones = torch.zeros((env.batch_size[0], n_agents), dtype=torch.bool)\n",
        "    nextt = TensorDict({\n",
        "      \"agents\": {\n",
        "            \"observation\": observation[:, 0:n_agents, :], # Make sure 'observation' is included here\n",
        "            \"reward\":episode_reward[:, 0:n_agents, :],\n",
        "          },\n",
        "\n",
        "       \"terminated\": dones.clone(),\n",
        "\n",
        "\n",
        "    }, batch_size=env.batch_size, device=env.device)\n",
        "    return nextt\n",
        "\n",
        "\n",
        "\n",
        "def _reset(self, tensordict=None, **kwargs):\n",
        "\n",
        "    if tensordict is None:\n",
        "      td = self.gen_params(batch_size=self.batch_size)\n",
        "      obsState_max=td['params','obsState_max'].clone().detach()\n",
        "      obsState_min=td['params','obsState_min'].clone().detach()\n",
        "      obsFuels_max=td['params','obsFuels_max'].clone().detach()\n",
        "      obsFuels_min=td['params','obsFuels_min'].clone().detach()\n",
        "      n_agents = self.n_agents\n",
        "\n",
        "\n",
        "\n",
        "      # Initialize agent list here\n",
        "      batchtentensor=[]\n",
        "      agents = [{} for _ in range(self.n_agents)]\n",
        "      agents = [{\"id\": i, \"data\": torch.randn(5)} for i in range(self.n_agents)]\n",
        "      agent_obs_list = [] # Collect observations in a list first\n",
        "      agent_tds = []\n",
        "      agent_obs_tensor=[]\n",
        "\n",
        "\n",
        "      # Iterate over the DataFrame\n",
        "      random_numbers = torch.rand((self.batch_size[0],5), generator=self.rng, device=self.device)\n",
        "      low_x=torch.cat((torch.mul(obsState_min[:,0:4],torch.ones(9,1)),obsFuels_min.T ),dim=1)\n",
        "      high_x=torch.cat((torch.mul(obsState_max[:,0:4],torch.ones(9,1)),obsFuels_max.T ),dim=1)\n",
        "      obs =  torch.add(torch.mul(random_numbers, torch.add(high_x, -low_x)), low_x)\n",
        "      obs= obs.float()\n",
        "          # Iterate over the DataFrame\n",
        "\n",
        "      for i, agent_obs in enumerate(obs):\n",
        "          agent_obs_list.append(agent_obs)\n",
        "          # Ensure agent_obs_tensor has the correct batch dimension\n",
        "      agent_obs_tensor = torch.stack(agent_obs_list, dim=0).unsqueeze(0)\n",
        "        # Now agent_obs_tensor has shape (1, num_agents, 5)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      dones = torch.zeros((self.batch_size[0], n_agents), dtype=torch.bool)\n",
        "\n",
        "      resett = TensorDict(\n",
        "        {\n",
        "        \"agents\": {  # Add \"agents\" key\n",
        "            \"observation\": agent_obs_tensor[:, 0:n_agents, :],  # Directly use agent_obs_tensor\n",
        "        },\n",
        "        \"terminated\": dones.clone(),\n",
        "\n",
        "    }, batch_size=self.batch_size[0], device=self.device)\n",
        "    return resett\n",
        "\n",
        "\n",
        "# @title Default title text\n",
        "def _make_spec(self, td_agents):\n",
        "    agent =[{}]*self.n_agents\n",
        "    action_specs = []\n",
        "    observation_specs = []\n",
        "    reward_specs = []\n",
        "\n",
        "    # Initialize result lists outside the loop\n",
        "\n",
        "\n",
        "    td = self.gen_params()\n",
        "    obsState_max=td_agents['params','obsState_max'].clone().detach()\n",
        "    obsState_min=td_agents['params','obsState_min'].clone().detach()\n",
        "    rewardState_max=td_agents['params','rewardState_max'].clone().detach()\n",
        "    rewardState_min=td_agents['params','rewardState_min'].clone().detach()\n",
        "    actionState_max=td_agents['params','actionState_max'].clone().detach()\n",
        "    actionState_min=td_agents['params','actionState_min'].clone().detach()\n",
        "    obsFuels_max=td_agents['params','obsFuels_max'].clone().detach()\n",
        "    obsFuels_min=td_agents['params','obsFuels_min'].clone().detach()\n",
        "    rewardFuels_max=td_agents['params','rewardFuels_max'].clone().detach()\n",
        "    rewardFuels_min=td_agents['params','rewardFuels_min'].clone().detach()\n",
        "    actionFuels_max=td_agents['params','actionFuels_max'].clone().detach()\n",
        "    actionFuels_min=td_agents['params','actionFuels_min'].clone().detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    low=torch.cat((torch.multiply(torch.ones((self.n_agents,1)),torch.tensor(self.rewstin.values)[:,None])),torch.reshape(torch.tensor(self.rewfmin.values),(self.n_agents, 1)),dim=1)\n",
        "    for i in range(self.n_agents):\n",
        "        agent[i][\"action_spec\"] =  BoundedTensorSpec(low = torch.cat((actionState_min[0:4],actionFuels_min[i:i+1]),1).reshape(1, 5),\n",
        "                                                     high = torch.cat((actionState_max[0:4],actionFuels_max[i:i+1]),1).reshape(1, 5),\n",
        "                                                     shape=(1,5),\n",
        "                                                     dtype=torch.float32),\n",
        "\n",
        "        agent[i][\"reward_spec\"] =  BoundedTensorSpec(low = torch.cat((rewardState_min[0:4],rewardFuels_min[i:i+1]),1).reshape(1, 5),\n",
        "                                                     high = torch.cat((rewardState_max[0:4],rewardFuels_max[i:i+1]),1).reshape(1, 5),\n",
        "                                                     shape=(1,5),\n",
        "                                                     dtype=torch.float32),\n",
        "\n",
        "        agent[i][\"reward_spec\"] =  BoundedTensorSpec(low = torch.cat((rewardState_min[0:4],rewardFuels_min[i:i+1]),1).reshape(1, 5),\n",
        "                                                     high = torch.cat((rewardState_max[0:4],rewardFuels_max[i:i+1]),1).reshape(1, 5),\n",
        "                                                     shape=(1,5),\n",
        "                                                     dtype=torch.float32),\n",
        "\n",
        "\n",
        "        agent[i][\"observation_spec\"]  = BoundedTensorSpec(low = torch.cat((obsState_min[0:4],obsFuels_min[i:i+1]),1).reshape(1, 5),\n",
        "                                                          high = torch.cat((obsState_max[0:4],obsFuels_max[i:i+1]),1).reshape(1, 5),\n",
        "                                                          shape=(1,5),\n",
        "                                                          dtype=torch.float32),\n",
        "\n",
        "\n",
        "        action_specs.append(agent[i][\"action_spec\"])\n",
        "        reward_specs.append(agent[i][\"reward_spec\"])\n",
        "        observation_specs.append(agent[i][\"observation_spec\"])\n",
        "\n",
        "\n",
        "\n",
        "# Construct CompositeSpec objects with the correct nesting and batch size\n",
        "def _make_spec_updated(self, td_agents):\n",
        "    agent =[{}]*self.n_agents\n",
        "    action_specs = []\n",
        "    observation_specs = []\n",
        "    reward_specs = []\n",
        "\n",
        "    # Initialize result lists outside the loop\n",
        "    obsState_max=td_agents['params','obsState_max'].clone().detach()\n",
        "    obsState_min=td_agents['params','obsState_min'].clone().detach()\n",
        "    rewardState_max=td_agents['params','rewardState_max'].clone().detach()\n",
        "    rewardState_min=td_agents['params','rewardState_min'].clone().detach()\n",
        "    actionState_max=td_agents['params','actionState_max'].clone().detach()\n",
        "\n",
        "    actionState_min=td_agents['params','actionState_min'].clone().detach()\n",
        "    obsFuels_max=td_agents['params','obsFuels_max'].clone().detach()\n",
        "    obsFuels_min=td_agents['params','obsFuels_min'].clone().detach()\n",
        "    rewardFuels_max=td_agents['params','rewardFuels_max'].clone().detach()\n",
        "    rewardFuels_min=td_agents['params','rewardFuels_min'].clone().detach()\n",
        "    actionFuels_max=td_agents['params','actionFuels_max'].clone().detach()\n",
        "    actionFuels_min=td_agents['params','actionFuels_min'].clone().detach()\n",
        "    result55=[]\n",
        "    result55=[]\n",
        "    result44=[]\n",
        "    result33=[]\n",
        "    result22=[]\n",
        "    result11=[]\n",
        "    result00=[]\n",
        "    result555=[]\n",
        "    result444=[]\n",
        "    result333=[]\n",
        "    result222=[]\n",
        "    result111=[]\n",
        "    result000=[]\n",
        "    for i in range(self.n_agents):  # Make sure the loop iterates 9 times\n",
        "        result55.append(torch.cat((actionState_min[0:4],actionFuels_min[i:i+1]),0).reshape(1, 5))\n",
        "        result44.append(torch.cat((actionState_max[0:4],actionFuels_max[i:i+1]),0).reshape(1, 5))\n",
        "        result33.append(torch.cat((rewardState_min[0:4],rewardFuels_min[i:i+1]),0).reshape(1, 5))\n",
        "        result22.append(torch.cat((rewardState_max[0:4],rewardFuels_max[i:i+1]),0).reshape(1, 5))\n",
        "        result11.append(torch.cat((obsState_min[0:4],obsFuels_min[i:i+1]),0).reshape(1, 5))\n",
        "        result00.append(torch.cat((obsState_max[0:4],obsFuels_max[i:i+1]),0).reshape(1, 5))\n",
        "\n",
        "    result555= torch.stack(result55,dim=0) # Transpose dimensions 0 and 1\n",
        "    result444 =torch.stack(result44,dim=0)\n",
        "    result333 =torch.stack(result33,dim=0)\n",
        "    result222 =torch.stack(result22,dim=0)\n",
        "    result111 =torch.stack(result11,dim=0)\n",
        "    result000 =torch.stack(result00,dim=0)\n",
        "    print(result555)\n",
        "\n",
        "\n",
        "    self.unbatched_action_spec = CompositeSpec(\n",
        "    {\"agents\": CompositeSpec(\n",
        "            {\"action\": BoundedTensorSpec(\n",
        "                low=result555.squeeze(1),\n",
        "                high=result444.squeeze(1),\n",
        "                shape=(self.n_agents,5),\n",
        "                dtype=torch.float32,\n",
        "             )}\n",
        "        )}\n",
        "    )\n",
        "\n",
        "    self.unbatched_reward_spec = CompositeSpec(\n",
        "    {\"agents\": CompositeSpec(\n",
        "            {\"reward\": BoundedTensorSpec(\n",
        "                low=result333.squeeze(1),\n",
        "                high=result222.squeeze(1),\n",
        "                shape=(self.n_agents,5),\n",
        "                dtype=torch.float32,\n",
        "             )}\n",
        "        )}\n",
        "    )\n",
        "\n",
        "\n",
        "    self.unbatched_observation_spec = CompositeSpec(  # Change to unbatched_observation_spec\n",
        "    {\"agents\": CompositeSpec(\n",
        "            {\"observation\": BoundedTensorSpec(\n",
        "                low=result111.squeeze(1),\n",
        "                high=result000.squeeze(1),\n",
        "                shape=(self.n_agents,5),\n",
        "                dtype=torch.float32,\n",
        "             )}\n",
        "        )}\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    self.unbatched_done_spec = DiscreteTensorSpec(n = 2,shape =torch.Size((self.n_agents,5)), dtype = torch.bool)\n",
        "\n",
        "    # Now you can expand the specs\n",
        "    self.unbatched_done_spec = DiscreteTensorSpec(\n",
        "        n=2, shape=torch.Size((self.n_agents,)), dtype=torch.bool\n",
        "    )\n",
        "\n",
        "    # Now you can expand the specs\n",
        "    self.action_spec = self.unbatched_action_spec.expand(\n",
        "        *self.batch_size, *self.unbatched_action_spec.shape\n",
        "    )\n",
        "    self.observation_spec = self.unbatched_observation_spec.expand(\n",
        "        *self.batch_size, *self.unbatched_observation_spec.shape\n",
        "    )  # Use unbatched_observation_spec\n",
        "    self.reward_spec = self.unbatched_reward_spec.expand(\n",
        "        *self.batch_size, *self.unbatched_reward_spec.shape\n",
        "    )\n",
        "    self.done_spec = self.unbatched_done_spec.expand(\n",
        "        *self.batch_size, *self.unbatched_done_spec.shape\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "def make_composite_from_td(td):\n",
        "    # custom function to convert a ``tensordict`` in a similar spec structure\n",
        "    # of unbounded values.\n",
        "    composite = CompositeSpec(\n",
        "        {\n",
        "            key: make_composite_from_td(tensor)\n",
        "            if isinstance(tensor, TensorDictBase)\n",
        "            else UnboundedContinuousTensorSpec(\n",
        "                dtype=tensor.dtype, device=tensor.device, shape=tensor.shape\n",
        "            )\n",
        "            for key, tensor in td.items()\n",
        "        },\n",
        "        shape=td.shape,\n",
        "    )\n",
        "    return composite\n",
        "\n",
        "\n",
        "\n",
        "def gen_params(batch_size=torch.Size()) -> TensorDictBase:\n",
        "    \"\"\"Returns a ``tensordict`` containing the input tensors.\"\"\"\n",
        "    if batch_size is None:\n",
        "      batch_size = []\n",
        "    my_object=DDataenv()\n",
        "    ac=my_object._get_obs_stats()\n",
        "    if batch_size:\n",
        "        # Assuming 'ac' is a dictionary of tensors, expand each tensor\n",
        "        ac = {k: torch.tensor(v).expand(*batch_size, *torch.tensor(v).shape)  for k, v in ac.items()} # Convert lists to tensors before expanding\n",
        "\n",
        "\n",
        "    td = TensorDict({\n",
        "\n",
        "          \"params\": ac,\n",
        "          }\n",
        "        ,\n",
        "        batch_size=batch_size,\n",
        "        device=torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\"),\n",
        "    )\n",
        "    if batch_size:\n",
        "      td = td.expand(batch_size).contiguous()\n",
        "    return td\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def _set_seed(self, seed:45):\n",
        "    rng = torch.manual_seed(seed)\n",
        "    self.rng = rng\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class AnFuelpriceEnv(EnvBase):\n",
        "    metadata = {\n",
        "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
        "        \"render_fps\": 30,\n",
        "    }\n",
        "    batch_locked = False\n",
        "\n",
        "    def __init__(self,td_params=None, seed=None, device=\"cpu\"):\n",
        "        if td_params is None:\n",
        "            td_params = self.gen_params()\n",
        "\n",
        "\n",
        "        # Extract the variables needed in _make_spec\n",
        "        self.n_agents = 9\n",
        "\n",
        "        self.agent_tds = []\n",
        "        self.agents = [{} for _ in range(self.n_agents)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        super().__init__(device=device, batch_size=[1])\n",
        "        self._make_spec(td_params)\n",
        "        if seed is None:\n",
        "            seed = torch.empty((), dtype=torch.int64).random_().item()\n",
        "        self.set_seed(seed)\n",
        "\n",
        "\n",
        "\n",
        "    # Helpers: _make_step and gen_params\n",
        "    gen_params =staticmethod(gen_params)\n",
        "    _make_spec = _make_spec_updated\n",
        "    # Mandatory methods: _step, _reset and _set_seed\n",
        "    _reset = _reset\n",
        "    _step = staticmethod(_step)\n",
        "    _set_seed = _set_seed\n",
        "\n",
        "env = AnFuelpriceEnv()\n",
        "print(\"\\n*action_spec:\", env.full_action_spec)\n",
        "print(\"\\n*reward_spec:\", env.full_reward_spec)\n",
        "print(\"\\n*done_spec:\", env.full_done_spec)\n",
        "print(\"\\n*observation_spec:\", env.observation_spec)\n",
        "\n",
        "print(\"\\n-action_keys:\", env.action_keys)\n",
        "print(\"\\n-reward_keys:\", env.reward_keys)\n",
        "print(\"\\n-done_keys:\", env.done_keys)\n",
        "\n",
        "print(\"input_spec:\", env.input_spec)\n",
        "print(\"action_spec (as defined by input_spec):\", env.action_spec)\n",
        "print(\"reward_spec:\", env.reward_spec)\n",
        "td = env.reset()\n",
        "print(\"reset tensordict\", td)\n",
        "check_env_specs(env)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NAzxW7kdGmSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toafL-i2pO0D",
        "outputId": "7be64fdb-f898-4da1-c60c-d6a25ec80074"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        agents: TensorDict(\n",
            "            fields={\n",
            "                observation: Tensor(shape=torch.Size([1, 9, 5]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                reward: Tensor(shape=torch.Size([1, 9, 5]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "            batch_size=torch.Size([1]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([1, 9]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([1]),\n",
            "    device=cpu,\n",
            "    is_shared=False)\n"
          ]
        }
      ],
      "source": [
        "ghhg=_step(tensordict)\n",
        "print(ghhg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBubg5W6pR_U",
        "outputId": "1453a145-cae7-4938-cc23-b28b860b790f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        agents: TensorDict(\n",
            "            fields={\n",
            "                observation: Tensor(shape=torch.Size([1, 9, 5]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "            batch_size=torch.Size([1]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([1, 9]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([1]),\n",
            "    device=cpu,\n",
            "    is_shared=False)\n"
          ]
        }
      ],
      "source": [
        "ghhhg = env._reset()  # Call _reset as a method of the env object\n",
        "print(ghhhg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6lB771bSJiU"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPnao8PIWOI5yBxD/5zmubO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}